{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import matplotlib.gridspec as gridspec\n",
    "from matplotlib.colors import LinearSegmentedColormap, ListedColormap\n",
    "import matplotlib.font_manager\n",
    "from matplotlib import rcParams, cm\n",
    "import scipy.stats as ss\n",
    "import h5py\n",
    "import glob\n",
    "import seaborn as sns\n",
    "import time\n",
    "import os\n",
    "import itertools\n",
    "import timeit\n",
    "import networkx as nx\n",
    "import scipy.io\n",
    "\n",
    "#import plotly.graph_objects as go \n",
    "\n",
    "#For ROI Maps\n",
    "from scipy.io import loadmat\n",
    "from skimage import measure\n",
    "from scipy import ndimage\n",
    "\n",
    "#For Fitting Baselines\n",
    "from scipy.optimize import curve_fit\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFilenames(mouse_numbers, mouse_days):\n",
    "    #Input lists of mouse numbers, days, and sessions to permute to give out directories and dictionary for filename\n",
    "    directories = []\n",
    "    filenames = {}\n",
    "    for m_num in mouse_numbers:\n",
    "        for m_day in mouse_days:\n",
    "            mouse_dir = '{}/{}/{}_10Hz_AudioVisual/motion_corrected/'.format(m_num, m_day,m_num)\n",
    "            directories.append(mouse_dir)\n",
    "                #filenames[mouse_dir] = 'trace_kyleFinal_BinaryVideo.hdf5'\n",
    "            filenames[mouse_dir] = 'processed_trace_final.h5'\n",
    "    return directories, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFilenames_2(mouse_numbers, mouse_days):\n",
    "    #Input lists of mouse numbers, days, and sessions to permute to give out directories and dictionary for filename\n",
    "    directories = []\n",
    "    filenames = {}\n",
    "    for m_num in mouse_numbers:\n",
    "        for m_day in mouse_days:\n",
    "            mouse_dir = '{}/{}/10Hz/{}_10Hz_AudioVisual/motion_corrected/'.format(m_num, m_day,m_num)\n",
    "            directories.append(mouse_dir)\n",
    "                #filenames[mouse_dir] = 'trace_kyleFinal_BinaryVideo.hdf5'\n",
    "            filenames[mouse_dir] = 'processed_trace_final.h5'\n",
    "    return directories, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineFilenames(base, dirs, fnDict):\n",
    "    #Combine Filenames into list for multiple directories with a common base.  fnDict is a dictionary of the filename for each directory\n",
    "    outFiles = []\n",
    "    for d in dirs:\n",
    "        outFiles.append(os.path.join(base+d+fnDict[d]))\n",
    "    return outFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608448/01062020/608448_10Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608451/01062020/608451_10Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608452/01062020/608452_10Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608450/03092020/608450_10Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/611311/03092020/611311_10Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/602101/03092020/602101_10Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608448/01172020/608448_10Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608451/07082020/608451_10Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608452/07082020/608452_10Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/611111/07082020/611111_10Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/602101/07082020/602101_10Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/612535/07082020/612535_10Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/615883/02052021/10Hz/615883_10Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/615883/03122021/10Hz/615883_10Hz_AudioVisual/motion_corrected/processed_trace_final.h5']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize Input Values\n",
    "#\n",
    "Base = '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/'\n",
    "Mice, Days = ([608448,608451,608452], ['01062020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files1 = combineFilenames(Base, Folders, Filenames)\n",
    "#Combine All Filenames into one List\n",
    "Mice, Days = ([608450,611311,602101], ['03092020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files2 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([608448], ['01172020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files3 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([608451,608452,611111,602101,612535], ['07082020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files4 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([615883], ['02052021','03122021'])\n",
    "Folders, Filenames = makeFilenames_2(Mice, Days)\n",
    "Files5 = combineFilenames(Base, Folders, Filenames)\n",
    "Files= Files1+Files2+Files3+Files4+Files5\n",
    "Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadFiles(allFiles, fieldName,multiIndex):\n",
    "    firstf = Files[0]\n",
    "    firstdir = firstf.split('/')[6]+'_'+firstf.split('/')[7]\n",
    "    f = h5py.File(firstf, 'r')\n",
    "    if multiIndex: #Adjust indexing for first DataFrame if using a multi-index\n",
    "        first_array = np.array(f[fieldName]).T\n",
    "        index_iterables = [[firstdir], range(first_array.shape[1])]\n",
    "        index = pd.MultiIndex.from_product(index_iterables, names=['mouse','cell_num'])\n",
    "        df = pd.DataFrame(data=first_array, columns=index)\n",
    "    else:\n",
    "        df = pd.DataFrame(data=np.array(f[fieldName]).T, columns=[firstdir])\n",
    "    df.index.name='Time'    \n",
    "\n",
    "    df_size = df.shape[0] #Determine Size of DataFrame\n",
    "    for f in Files[1:]: #Loop through remaining files and add to DataFrame\n",
    "        fdir = f.split('/')[6]+'_'+f.split('/')[7] #Current Filename/Dir\n",
    "        f = h5py.File(f, 'r')\n",
    "        if multiIndex: #Iteratively add multiIndexed DataFrames\n",
    "            data_arr = np.array(f[fieldName]).T\n",
    "            index_iterables = [[fdir], range(data_arr.shape[1])]\n",
    "            index = pd.MultiIndex.from_product(index_iterables, names=['mouse', 'cell_num'])\n",
    "            df = df.join(pd.DataFrame(data=data_arr, columns=index))\n",
    "    drop_index = df.index[df.isna().any(axis='columns')]\n",
    "    df = df.drop(drop_index)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_traces_df=loadFiles(Files, 'trace',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>mouse</th>\n",
       "      <th colspan=\"10\" halign=\"left\">608448_01062020</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">615883_03122021</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_num</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>42</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43196</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43200 rows Ã— 3324 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "mouse    608448_01062020                                               ...  \\\n",
       "cell_num              0    1    2    3    4    5    6    7    8    9   ...   \n",
       "Time                                                                   ...   \n",
       "0                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "...                  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "43195                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "43196                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "43197                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "43198                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "43199                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "mouse    615883_03122021                                               \n",
       "cell_num              42   43   44   45   46   47   48   49   50   51  \n",
       "Time                                                                   \n",
       "0                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...                  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "43195                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "43196                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "43197                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "43198                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "43199                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[43200 rows x 3324 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onset_binary_traces_df=loadFiles(Files, 'onset_binary_trace',True)\n",
    "onset_binary_traces_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_traces_df=loadFiles(Files, 'binary_trace',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFilenames(mouse_numbers, mouse_days):\n",
    "    #Input lists of mouse numbers, days, and sessions to permute to give out directories and dictionary for filename\n",
    "    directories = []\n",
    "    filenames = {}\n",
    "    for m_num in mouse_numbers:\n",
    "        for m_day in mouse_days:\n",
    "            mouse_dir = '{}/{}/{}_10Hz_AudioVisual/motion_corrected/'.format(m_num, m_day,m_num)\n",
    "            directories.append(mouse_dir)\n",
    "                #filenames[mouse_dir] = 'trace_kyleFinal_BinaryVideo.hdf5'\n",
    "            filenames[mouse_dir] = 'LFP_ts.h5'\n",
    "    return directories, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFilenames_2(mouse_numbers, mouse_days):\n",
    "    #Input lists of mouse numbers, days, and sessions to permute to give out directories and dictionary for filename\n",
    "    directories = []\n",
    "    filenames = {}\n",
    "    for m_num in mouse_numbers:\n",
    "        for m_day in mouse_days:\n",
    "            mouse_dir = '{}/{}/10Hz/{}_10Hz_AudioVisual/motion_corrected/'.format(m_num, m_day,m_num)\n",
    "            directories.append(mouse_dir)\n",
    "                #filenames[mouse_dir] = 'trace_kyleFinal_BinaryVideo.hdf5'\n",
    "            filenames[mouse_dir] = 'LFP_ts.h5'\n",
    "    return directories, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineFilenames(base, dirs, fnDict):\n",
    "    #Combine Filenames into list for multiple directories with a common base.  fnDict is a dictionary of the filename for each directory\n",
    "    outFiles = []\n",
    "    for d in dirs:\n",
    "        outFiles.append(os.path.join(base+d+fnDict[d]))\n",
    "    return outFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Initialize Input Values\n",
    "#\n",
    "Base = '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/'\n",
    "Mice, Days = ([608451,608452], ['01062020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files1 = combineFilenames(Base, Folders, Filenames)\n",
    "#Combine All Filenames into one List\n",
    "Mice, Days = ([608450,611311,602101], ['03092020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files2 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([608448], ['01172020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files3 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([608451,608452,611111,602101,612535], ['07082020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files4 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([615883], ['02052021','03122021'])\n",
    "Folders, Filenames = makeFilenames_2(Mice, Days)\n",
    "Files5 = combineFilenames(Base, Folders, Filenames)\n",
    "LFP_Files= Files1+Files2+Files3+Files4+Files5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a good way to store stim onsets and offsets \n",
    "def load_onset_offset_2(files,fieldName):\n",
    "    firstf = Files[0]\n",
    "    \n",
    "    firstdir = firstf.split('/')[6]+'_'+firstf.split('/')[7]\n",
    "    f = h5py.File(firstf, 'r')\n",
    "    data=np.array(f[fieldName])-1\n",
    "    data=np.reshape(data,(1,5))\n",
    "    df = pd.DataFrame(data)\n",
    "    df.index=[firstdir]\n",
    "   \n",
    "    for f in files[0:]: #Loop through remaining files and add to DataFrame\n",
    "        fdir = f.split('/')[6]+'_'+f.split('/')[7] #Current Filename/Dir\n",
    "        f = h5py.File(f, 'r')\n",
    "        data=np.array(f[fieldName])-1\n",
    "        data=np.reshape(data,(1,5))\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1.index=[fdir]\n",
    "        df = pd.concat([df,df1])\n",
    "    df=df.astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_onsets_df=load_onset_offset_2(LFP_Files,'Stim_onset')\n",
    "stim_offsets_df=load_onset_offset_2(LFP_Files,'Stim_offset')\n",
    "stim_time=stim_offsets_df-stim_onsets_df+1\n",
    "Total_frames_stim = pd.DataFrame(stim_time.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude the min after stim\n",
    "def get_baseline_frames_index(sess_no):\n",
    "    stim_on_inds=stim_onsets_df.loc[sess_no,:]\n",
    "    stim_off_inds=stim_offsets_df.loc[sess_no,:]\n",
    "\n",
    "    baseline_indices=np.arange(0,stim_on_inds[0])\n",
    "    for i in np.arange(0,4,1):\n",
    "        b=np.arange(stim_off_inds[i]+1200,stim_on_inds[i+1])\n",
    "        baseline_indices=np.concatenate((baseline_indices,b))\n",
    "    b= np.arange(stim_off_inds[4]+1200,42000,1)\n",
    "    baseline_indices=np.concatenate((baseline_indices,b))\n",
    "    return baseline_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stim_frames_index(sess_no):\n",
    "    stim_on_inds=stim_onsets_df.loc[sess_no,:]\n",
    "    stim_off_inds=stim_offsets_df.loc[sess_no,:]\n",
    "    stim_indices=np.arange(stim_on_inds[0],stim_off_inds[0]+1,1)\n",
    "    for i in np.arange(1,5,1):\n",
    "        b=np.arange(stim_on_inds[i],stim_off_inds[i]+1,1)\n",
    "        stim_indices=np.concatenate((stim_indices,b))\n",
    "    return stim_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_nan_motion_frames(sess_name):\n",
    "    motion=np.array(motion_df.loc[sess_name,:])\n",
    "    motion=np.squeeze(motion)\n",
    "    nan_motion_frames=np.argwhere(np.isnan(motion))\n",
    "    baseline_indices=get_baseline_frames_index(sess_name)\n",
    "    c=np.intersect1d(baseline_indices,nan_motion_frames)\n",
    "    common_indices=np.setdiff1d(baseline_indices,c)\n",
    "    return common_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFilenames_motion(mouse_numbers, mouse_days):\n",
    "    #Input lists of mouse numbers, days, and sessions to permute to give out directories and dictionary for filename\n",
    "    directories = []\n",
    "    filenames = {}\n",
    "    for m_num in mouse_numbers:\n",
    "        for m_day in mouse_days:\n",
    "            mouse_dir = '{}/{}/{}_10Hz_AudioVisual/motion_corrected/'.format(m_num, m_day,m_num)\n",
    "            directories.append(mouse_dir)\n",
    "                #filenames[mouse_dir] = 'trace_kyleFinal_BinaryVideo.hdf5'\n",
    "            filenames[mouse_dir] = 'processed_motion.h5'\n",
    "    return directories, filenames\n",
    "def makeFilenames_motion_2(mouse_numbers, mouse_days):\n",
    "    #Input lists of mouse numbers, days, and sessions to permute to give out directories and dictionary for filename\n",
    "    directories = []\n",
    "    filenames = {}\n",
    "    for m_num in mouse_numbers:\n",
    "        for m_day in mouse_days:\n",
    "            mouse_dir = '{}/{}/10Hz/{}_10Hz_AudioVisual/motion_corrected/'.format(m_num, m_day,m_num)\n",
    "            directories.append(mouse_dir)\n",
    "                #filenames[mouse_dir] = 'trace_kyleFinal_BinaryVideo.hdf5'\n",
    "            filenames[mouse_dir] = 'processed_motion.h5'\n",
    "    return directories, filenames\n",
    "Base = '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/'\n",
    "Mice, Days = ([608448,608451,608452], ['01062020'])\n",
    "Folders, Filenames = makeFilenames_motion(Mice, Days)\n",
    "Files1 = combineFilenames(Base, Folders, Filenames)\n",
    "#Combine All Filenames into one List\n",
    "Mice, Days = ([608450,611311,602101], ['03092020'])\n",
    "Folders, Filenames = makeFilenames_motion(Mice, Days)\n",
    "Files2 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([608448], ['01172020'])\n",
    "Folders, Filenames = makeFilenames_motion(Mice, Days)\n",
    "Files3 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([608451,608452,611111,602101,612535], ['07082020'])\n",
    "Folders, Filenames = makeFilenames_motion(Mice, Days)\n",
    "Files4 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([615883], ['02052021','03122021'])\n",
    "Folders, Filenames = makeFilenames_motion_2(Mice, Days)\n",
    "Files5 = combineFilenames(Base, Folders, Filenames)\n",
    "motion_Files= Files1+Files2+Files3+Files4+Files5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a good way to store stim onsets and offsets \n",
    "def load_motion(Files,fieldName):\n",
    "    firstf = Files[0]\n",
    "    firstdir = firstf.split('/')[6]+'_'+firstf.split('/')[7]\n",
    "    f = h5py.File(firstf, 'r')\n",
    "    data=np.array(f[fieldName])\n",
    "    df = pd.DataFrame(data)\n",
    "    df.index=[firstdir]\n",
    "   \n",
    "    for f in Files[1:]: #Loop through remaining files and add to DataFrame\n",
    "        fdir = f.split('/')[6]+'_'+f.split('/')[7] #Current Filename/Dir\n",
    "        f = h5py.File(f, 'r')\n",
    "        data=np.array(f[fieldName])\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1.index=[fdir]\n",
    "        df = pd.concat([df,df1])\n",
    "        #drop last minute\n",
    "        df = df.iloc[: , :-1200]\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "motion_df=load_motion(motion_Files,'speed_trace')\n",
    "moving_period_df=load_motion(motion_Files,'moving_period')\n",
    "stationary_period_df=load_motion(motion_Files,'stationary_period')\n",
    "acceleration_period_df=load_motion(motion_Files,'aceleration_period')\n",
    "motion_onsets_df=load_motion(motion_Files,'motion_onset_with')\n",
    "motion_onsets_df_without=load_motion(motion_Files,'motion_onset_without')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_firing_rate_cell_wise(traces_df,sess_no):\n",
    "    onset_binary_traces=traces_df[sess_no]\n",
    "    onset_binary_traces=onset_binary_traces.T\n",
    "    baseline_indices=get_baseline_frames_index(sess_no)\n",
    "    temp_df=onset_binary_traces.loc[:,baseline_indices]\n",
    "    Ncells = temp_df.shape[0]\n",
    "    out= np.zeros((Ncells,1))\n",
    "    for cell in np.arange(0,Ncells,1):\n",
    "        #out[cell]=out[cell]+np.array(np.where(temp_df.loc[cell,:]==1)).size\n",
    "        out[cell]=out[cell]+np.sum(temp_df.loc[cell,:])\n",
    "    tot_frames=(baseline_indices.shape[0])\n",
    "    p=out/tot_frames*1200\n",
    "    \n",
    "    return p,np.mean(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.67471029, 3.08533303, 2.17592451, 2.09689569, 1.98206658,\n",
       "       2.26821755, 3.0444662 , 2.87247893, 3.6658552 , 2.84028403,\n",
       "       3.0323705 , 3.93494979, 2.41478742, 2.53341471])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Method 1\n",
    "sess_list=[]\n",
    "for mouse, cell_df in onset_binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)\n",
    "sess_list\n",
    "mean_p=np.zeros(len(sess_list))\n",
    "\n",
    "for i in np.arange(0,len(sess_list),1):\n",
    "    sess_name=sess_list[i]\n",
    "    mean_p[i]=(baseline_firing_rate_cell_wise(onset_binary_traces_df,sess_name)[1])\n",
    "mean_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sess list</th>\n",
       "      <th>Mean baseline firing rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>602101_03092020</td>\n",
       "      <td>1.674710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>602101_07082020</td>\n",
       "      <td>3.085333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>608448_01062020</td>\n",
       "      <td>2.175925</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>608448_01172020</td>\n",
       "      <td>2.096896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>608450_03092020</td>\n",
       "      <td>1.982067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>608451_01062020</td>\n",
       "      <td>2.268218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>608451_07082020</td>\n",
       "      <td>3.044466</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>608452_01062020</td>\n",
       "      <td>2.872479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>608452_07082020</td>\n",
       "      <td>3.665855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>611111_07082020</td>\n",
       "      <td>2.840284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>611311_03092020</td>\n",
       "      <td>3.032371</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>612535_07082020</td>\n",
       "      <td>3.934950</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>615883_02052021</td>\n",
       "      <td>2.414787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>615883_03122021</td>\n",
       "      <td>2.533415</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sess list  Mean baseline firing rate\n",
       "0   602101_03092020                   1.674710\n",
       "1   602101_07082020                   3.085333\n",
       "2   608448_01062020                   2.175925\n",
       "3   608448_01172020                   2.096896\n",
       "4   608450_03092020                   1.982067\n",
       "5   608451_01062020                   2.268218\n",
       "6   608451_07082020                   3.044466\n",
       "7   608452_01062020                   2.872479\n",
       "8   608452_07082020                   3.665855\n",
       "9   611111_07082020                   2.840284\n",
       "10  611311_03092020                   3.032371\n",
       "11  612535_07082020                   3.934950\n",
       "12  615883_02052021                   2.414787\n",
       "13  615883_03122021                   2.533415"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a dataframe with sess_list and mean_p\n",
    "df = {'Sess list' : pd.Series(sess_list), 'Mean baseline firing rate' : pd.Series(mean_p)}\n",
    "mean_p_df=pd.DataFrame(df)\n",
    "mean_p_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Contains given substring \n"
     ]
    }
   ],
   "source": [
    "## Split them as GCamp7 and somaGCamp7 - think of a clever way!\n",
    "#GCamp7-608448,608450,608452,612535,615883\n",
    "#somaGCamp7-6085451,602101,611111,611311\n",
    "if sess_list[0].find('602101') != -1: \n",
    "    print (\"Contains given substring \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.7880284507906787 2.622881289646681\n",
      "0.7740640064182476 0.48911851880563595\n",
      "2.5242017175093556 2.8402840284028406\n",
      "Ttest_indResult(statistic=0.42887142186687943, pvalue=0.6762951169532849)\n"
     ]
    }
   ],
   "source": [
    "G_baseline_firing_rate_10Hz=[mean_p[2],mean_p[3],mean_p[4],mean_p[7],mean_p[8],mean_p[11]]\n",
    "soma_baseline_firing_rate_10Hz =[mean_p[0],mean_p[1],mean_p[5],mean_p[6],mean_p[9],mean_p[10],mean_p[12]]\n",
    "print(np.mean(G_baseline_firing_rate_10Hz),np.mean(soma_baseline_firing_rate_10Hz))\n",
    "print(np.std(G_baseline_firing_rate_10Hz),np.std(soma_baseline_firing_rate_10Hz))\n",
    "print(np.median(G_baseline_firing_rate_10Hz),np.median(soma_baseline_firing_rate_10Hz))\n",
    "print(ss.ttest_ind(G_baseline_firing_rate_10Hz,soma_baseline_firing_rate_10Hz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['602101_03092020', '602101_07082020', '608448_01062020', '608448_01172020', '608450_03092020', '608451_01062020', '608451_07082020', '608452_01062020', '608452_07082020', '611111_07082020', '611311_03092020', '612535_07082020', '615883_02052021', '615883_03122021']\n"
     ]
    }
   ],
   "source": [
    "## Store in .h5 files \n",
    "sess_list=[]\n",
    "for mouse, cell_df in binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)\n",
    "print(sess_list)\n",
    "f1 = h5py.File(\"Event_rate_10Hz_per_min_final.h5\", 'w')\n",
    "label=np.zeros(len(sess_list))\n",
    "for i in np.arange(0,len(sess_list),1):\n",
    "    sess_name=sess_list[i]\n",
    "    mean_p=(baseline_firing_rate_cell_wise(onset_binary_traces_df,sess_name)[1])\n",
    "    mean_p_bin=(baseline_firing_rate_cell_wise(binary_traces_df,sess_name)[1])\n",
    "    if sess_list[i].find('608448') != -1 or sess_list[i].find('608450') != -1 or sess_list[i].find('608452') != -1 or sess_list[i].find('612535') != -1 or sess_list[i].find('615883') != -1: \n",
    "        label[i]=1\n",
    "    if sess_list[i].find('602101') != -1 or sess_list[i].find('608451') != -1 or sess_list[i].find('611311') != -1 or sess_list[i].find('611111') != -1: \n",
    "        label[i]=2\n",
    "    dset1 = f1.create_dataset(sess_list[i]+'_onset', data=mean_p)\n",
    "    dset2 = f1.create_dataset(sess_list[i]+'_bin', data=mean_p_bin)\n",
    "dset3=f1.create_dataset('GCamp_version', data=label)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def upper_tri_masking(A):\n",
    "    m = A.shape[0]\n",
    "    r = np.arange(m)\n",
    "    mask = r[:,None] < r\n",
    "    return A[mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Redo this function!\n",
    "def baseline_corr(sess_name):\n",
    "    traces= binary_traces_df[sess_name].T\n",
    "    speed_df=np.array(traces)\n",
    "    corr_matrix=np.corrcoef(speed_df)\n",
    "    corr_list=upper_tri_masking(corr_matrix)\n",
    "    mean_corr=np.nanmean(corr_list)\n",
    "    median_corr=np.nanmedian(corr_list)\n",
    "    return mean_corr,median_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_before_first_stim(sess_name):\n",
    "    traces= binary_traces_df[sess_name].T\n",
    "    Ncells=traces.shape[0]\n",
    "    common_indices=remove_nan_motion_frames(sess_name)\n",
    "    stim_on_inds=stim_onsets_df.loc[sess_name,:]\n",
    "    indices=np.arange(common_indices[0],stim_on_inds[0]+1,1)\n",
    "    speed_index = indices\n",
    "    speed_df=np.array(traces.loc[:,indices])\n",
    "    corr_matrix=np.corrcoef(speed_df)\n",
    "    obs_corr_list=upper_tri_masking(corr_matrix)\n",
    "    mean_corr=np.nanmean(obs_corr_list)\n",
    "    median_corr=np.nanmedian(obs_corr_list)\n",
    "    return mean_corr,median_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_before_first_stim2(sess_name):\n",
    "    traces= binary_traces_df[sess_name].T\n",
    "    Ncells=traces.shape[0]\n",
    "    common_indices=remove_nan_motion_frames(sess_name)\n",
    "    stim_on_inds=stim_onsets_df.loc[sess_name,:]\n",
    "    indices=np.arange(common_indices[0],stim_on_inds[0]+1,1)\n",
    "    speed_index = indices\n",
    "    speed_df=np.array(traces.loc[:,indices])\n",
    "    corr_matrix=np.corrcoef(speed_df)\n",
    "    obs_corr_list=upper_tri_masking(corr_matrix)\n",
    "    mean_corr=np.nanmean(obs_corr_list)\n",
    "    median_corr=np.nanmedian(obs_corr_list)\n",
    "    return obs_corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanlabadmins/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/hanlabadmins/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.02423728, 0.02387254, 0.00813154, 0.01278351, 0.0122976 ,\n",
       "       0.01264545, 0.01743308, 0.00880574, 0.00985052, 0.01845124,\n",
       "       0.00814773, 0.01333127, 0.00891723, 0.00984987])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_list=[]\n",
    "for mouse, cell_df in onset_binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)\n",
    "sess_list\n",
    "mean_corr=np.zeros(len(sess_list))\n",
    "\n",
    "for i in np.arange(0,len(sess_list),1):\n",
    "    sess_name=sess_list[i]\n",
    "    mean_corr[i],_=baseline_corr(sess_name)\n",
    "mean_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00361897, -0.00124769, -0.00783264, -0.00609209, -0.00411894,\n",
       "       -0.00505094, -0.00020826, -0.00446961, -0.00561763, -0.00339681,\n",
       "       -0.00685324, -0.00515387, -0.00427042, -0.00919991])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sess_list=[]\n",
    "for mouse, cell_df in onset_binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)\n",
    "sess_list\n",
    "median_corr=np.zeros(len(sess_list))\n",
    "\n",
    "for i in np.arange(0,len(sess_list),1):\n",
    "    sess_name=sess_list[i]\n",
    "    _,median_corr[i]=corr_before_first_stim(sess_name)\n",
    "median_corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sess list</th>\n",
       "      <th>Median baseline corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>602101_03092020</td>\n",
       "      <td>-0.003619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>602101_07082020</td>\n",
       "      <td>-0.001248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>608448_01062020</td>\n",
       "      <td>-0.007833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>608448_01172020</td>\n",
       "      <td>-0.006092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>608450_03092020</td>\n",
       "      <td>-0.004119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>608451_01062020</td>\n",
       "      <td>-0.005051</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>608451_07082020</td>\n",
       "      <td>-0.000208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>608452_01062020</td>\n",
       "      <td>-0.004470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>608452_07082020</td>\n",
       "      <td>-0.005618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>611111_07082020</td>\n",
       "      <td>-0.003397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>611311_03092020</td>\n",
       "      <td>-0.006853</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>612535_07082020</td>\n",
       "      <td>-0.005154</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>615883_02052021</td>\n",
       "      <td>-0.004270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>615883_03122021</td>\n",
       "      <td>-0.009200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sess list  Median baseline corr\n",
       "0   602101_03092020             -0.003619\n",
       "1   602101_07082020             -0.001248\n",
       "2   608448_01062020             -0.007833\n",
       "3   608448_01172020             -0.006092\n",
       "4   608450_03092020             -0.004119\n",
       "5   608451_01062020             -0.005051\n",
       "6   608451_07082020             -0.000208\n",
       "7   608452_01062020             -0.004470\n",
       "8   608452_07082020             -0.005618\n",
       "9   611111_07082020             -0.003397\n",
       "10  611311_03092020             -0.006853\n",
       "11  612535_07082020             -0.005154\n",
       "12  615883_02052021             -0.004270\n",
       "13  615883_03122021             -0.009200"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a dataframe with sess_list and mean_p\n",
    "df = {'Sess list' : pd.Series(sess_list), 'Median baseline corr' : pd.Series(median_corr)}\n",
    "median_corr_df=pd.DataFrame(df)\n",
    "median_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.010299730383348573 0.015030985002482594\n",
      "0.0014640556855052853 0.004997382925627378\n",
      "0.009875410949621431 0.015561313359549947\n",
      "Ttest_indResult(statistic=-2.0588248606070576, pvalue=0.06399492488485481)\n",
      "RanksumsResult(statistic=-1.8571428571428572, pvalue=0.06329083223334525)\n"
     ]
    }
   ],
   "source": [
    "G_baseline_firing_corr_10Hz=[mean_corr[2],mean_corr[3],mean_corr[4],mean_corr[7],mean_corr[8],mean_corr[11]]\n",
    "soma_baseline_firing_corr_10Hz =[mean_corr[0],mean_corr[1],mean_corr[5],mean_corr[6],mean_corr[9],mean_corr[10],mean_corr[12]]\n",
    "print(np.mean(G_baseline_firing_corr_10Hz),np.mean(soma_baseline_firing_corr_10Hz))\n",
    "print(np.std(G_baseline_firing_corr_10Hz),np.std(soma_baseline_firing_corr_10Hz))\n",
    "print(np.median(G_baseline_firing_corr_10Hz),np.median(soma_baseline_firing_corr_10Hz))\n",
    "print(ss.ttest_ind(G_baseline_firing_corr_10Hz,soma_baseline_firing_corr_10Hz))\n",
    "print(ss.ranksums(G_baseline_firing_corr_10Hz,soma_baseline_firing_corr_10Hz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['602101_03092020', '602101_07082020', '608448_01062020', '608448_01172020', '608450_03092020', '608451_01062020', '608451_07082020', '608452_01062020', '608452_07082020', '611111_07082020', '611311_03092020', '612535_07082020', '615883_02052021', '615883_03122021']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanlabadmins/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/hanlabadmins/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "## Store in .h5 files \n",
    "sess_list=[]\n",
    "for mouse, cell_df in binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)\n",
    "print(sess_list)\n",
    "f1 = h5py.File(\"Baseline_mean_corr_10Hz_final.h5\", 'w')\n",
    "label=np.zeros(len(sess_list))\n",
    "mean_corr=np.zeros(len(sess_list))\n",
    "for i in np.arange(0,len(sess_list),1):\n",
    "    sess_name=sess_list[i]\n",
    "    mean_corr[i],_=baseline_corr(sess_name)\n",
    "    \n",
    "    if sess_list[i].find('608448') != -1 or sess_list[i].find('608450') != -1 or sess_list[i].find('608452') != -1 or sess_list[i].find('612535') != -1 or sess_list[i].find('615883') != -1: \n",
    "        label[i]=1\n",
    "    if sess_list[i].find('602101') != -1 or sess_list[i].find('608451') != -1 or sess_list[i].find('611311') != -1 or sess_list[i].find('611111') != -1: \n",
    "        label[i]=2\n",
    "    dset1 = f1.create_dataset(sess_list[i], data=mean_corr[i])\n",
    "dset3=f1.create_dataset('GCamp_version', data=label)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['602101_03092020', '602101_07082020', '608448_01062020', '608448_01172020', '608450_03092020', '608451_01062020', '608451_07082020', '608452_01062020', '608452_07082020', '611111_07082020', '611311_03092020', '612535_07082020', '615883_02052021', '615883_03122021']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanlabadmins/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/hanlabadmins/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "## Store in .h5 files \n",
    "sess_list=[]\n",
    "for mouse, cell_df in binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)\n",
    "print(sess_list)\n",
    "f1 = h5py.File(\"Baseline_median_corr_10Hz_before_first_stim_final.h5\", 'w')\n",
    "label=np.zeros(len(sess_list))\n",
    "median_corr=np.zeros(len(sess_list))\n",
    "for i in np.arange(0,len(sess_list),1):\n",
    "    sess_name=sess_list[i]\n",
    "    _,median_corr[i]=corr_before_first_stim(sess_name)\n",
    "    \n",
    "    if sess_list[i].find('608448') != -1 or sess_list[i].find('608450') != -1 or sess_list[i].find('608452') != -1 or sess_list[i].find('612535') != -1 or sess_list[i].find('615883') != -1: \n",
    "        label[i]=1\n",
    "    if sess_list[i].find('602101') != -1 or sess_list[i].find('608451') != -1 or sess_list[i].find('611311') != -1 or sess_list[i].find('611111') != -1: \n",
    "        label[i]=2\n",
    "    dset1 = f1.create_dataset(sess_list[i], data=median_corr[i])\n",
    "dset3=f1.create_dataset('GCamp_version', data=label)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['602101_03092020', '602101_07082020', '608448_01062020', '608448_01172020', '608450_03092020', '608451_01062020', '608451_07082020', '608452_01062020', '608452_07082020', '611111_07082020', '611311_03092020', '612535_07082020', '615883_02052021', '615883_03122021']\n"
     ]
    }
   ],
   "source": [
    "## Store in .h5 files \n",
    "sess_list=[]\n",
    "for mouse, cell_df in binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)\n",
    "print(sess_list)\n",
    "f1 = h5py.File(\"Baseline_median_corr_10Hz_final.h5\", 'w')\n",
    "label=np.zeros(len(sess_list))\n",
    "median_corr=np.zeros(len(sess_list))\n",
    "for i in np.arange(0,len(sess_list),1):\n",
    "    sess_name=sess_list[i]\n",
    "    _,median_corr[i]=baseline_corr(sess_name)\n",
    "    \n",
    "    if sess_list[i].find('608448') != -1 or sess_list[i].find('608450') != -1 or sess_list[i].find('608452') != -1 or sess_list[i].find('612535') != -1 or sess_list[i].find('615883') != -1: \n",
    "        label[i]=1\n",
    "    if sess_list[i].find('602101') != -1 or sess_list[i].find('608451') != -1 or sess_list[i].find('611311') != -1 or sess_list[i].find('611111') != -1: \n",
    "        label[i]=2\n",
    "    dset1 = f1.create_dataset(sess_list[i], data=median_corr[i])\n",
    "dset3=f1.create_dataset('GCamp_version', data=label)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['602101_03092020', '602101_07082020', '608448_01062020', '608448_01172020', '608450_03092020', '608451_01062020', '608451_07082020', '608452_01062020', '608452_07082020', '611111_07082020', '611311_03092020', '612535_07082020', '615883_02052021', '615883_03122021']\n"
     ]
    }
   ],
   "source": [
    "## Store in .h5 files \n",
    "sess_list=[]\n",
    "for mouse, cell_df in binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)\n",
    "print(sess_list)\n",
    "f1 = h5py.File(\"Baseline_median_corr_10Hz_before_first_stim_final.h5\", 'w')\n",
    "label=np.zeros(len(sess_list))\n",
    "median_corr=np.zeros(len(sess_list))\n",
    "for i in np.arange(0,len(sess_list),1):\n",
    "    sess_name=sess_list[i]\n",
    "    _,median_corr[i]=corr_before_first_stim(sess_name)\n",
    "    \n",
    "    if sess_list[i].find('608448') != -1 or sess_list[i].find('608450') != -1 or sess_list[i].find('608452') != -1 or sess_list[i].find('612535') != -1 or sess_list[i].find('615883') != -1: \n",
    "        label[i]=1\n",
    "    if sess_list[i].find('602101') != -1 or sess_list[i].find('608451') != -1 or sess_list[i].find('611311') != -1 or sess_list[i].find('611111') != -1: \n",
    "        label[i]=2\n",
    "    dset1 = f1.create_dataset(sess_list[i], data=median_corr[i])\n",
    "dset3=f1.create_dataset('GCamp_version', data=label)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['602101_03092020', '602101_07082020', '608448_01062020', '608448_01172020', '608450_03092020', '608451_01062020', '608451_07082020', '608452_01062020', '608452_07082020', '611111_07082020', '611311_03092020', '612535_07082020', '615883_02052021', '615883_03122021']\n"
     ]
    }
   ],
   "source": [
    "## Store in .h5 files \n",
    "sess_list=[]\n",
    "for mouse, cell_df in binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)\n",
    "print(sess_list)\n",
    "f1 = h5py.File(\"Baseline_corr_list_before_first_stim_10Hz.h5\", 'w')\n",
    "label=np.zeros(len(sess_list))\n",
    "for i in np.arange(0,len(sess_list),1):\n",
    "    sess_name=sess_list[i]\n",
    "    corr_list=corr_before_first_stim2(sess_name)\n",
    "    \n",
    "    if sess_list[i].find('608448') != -1 or sess_list[i].find('608450') != -1 or sess_list[i].find('608452') != -1 or sess_list[i].find('612535') != -1 or sess_list[i].find('615883') != -1: \n",
    "        label[i]=1\n",
    "    if sess_list[i].find('602101') != -1 or sess_list[i].find('608451') != -1 or sess_list[i].find('611311') != -1 or sess_list[i].find('611111') != -1: \n",
    "        label[i]=2\n",
    "    dset1 = f1.create_dataset(sess_list[i], data=corr_list)\n",
    "dset3=f1.create_dataset('GCamp_version', data=label)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 145 Hz sessions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFilenames(mouse_numbers, mouse_days):\n",
    "    #Input lists of mouse numbers, days, and sessions to permute to give out directories and dictionary for filename\n",
    "    directories = []\n",
    "    filenames = {}\n",
    "    for m_num in mouse_numbers:\n",
    "        for m_day in mouse_days:\n",
    "            mouse_dir = '{}/{}/{}_145Hz_AudioVisual/motion_corrected/'.format(m_num, m_day,m_num)\n",
    "            directories.append(mouse_dir)\n",
    "                #filenames[mouse_dir] = 'trace_kyleFinal_BinaryVideo.hdf5'\n",
    "            filenames[mouse_dir] = 'processed_trace_final.h5'\n",
    "    return directories, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFilenames_2(mouse_numbers, mouse_days):\n",
    "    #Input lists of mouse numbers, days, and sessions to permute to give out directories and dictionary for filename\n",
    "    directories = []\n",
    "    filenames = {}\n",
    "    for m_num in mouse_numbers:\n",
    "        for m_day in mouse_days:\n",
    "            mouse_dir = '{}/{}/145Hz/{}_145Hz_AudioVisual/motion_corrected/'.format(m_num, m_day,m_num)\n",
    "            directories.append(mouse_dir)\n",
    "                #filenames[mouse_dir] = 'trace_kyleFinal_BinaryVideo.hdf5'\n",
    "            filenames[mouse_dir] = 'processed_trace_final.h5'\n",
    "    return directories, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineFilenames(base, dirs, fnDict):\n",
    "    #Combine Filenames into list for multiple directories with a common base.  fnDict is a dictionary of the filename for each directory\n",
    "    outFiles = []\n",
    "    for d in dirs:\n",
    "        outFiles.append(os.path.join(base+d+fnDict[d]))\n",
    "    return outFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608448/01102020/608448_145Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608451/01102020/608451_145Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608452/01102020/608452_145Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/611111/03112020/611111_145Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/611311/03112020/611311_145Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/602101/03112020/602101_145Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608450/01172020/608450_145Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608451/07012020/608451_145Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608452/07012020/608452_145Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/611111/07012020/611111_145Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/612535/07022020/612535_145Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/602101/07022020/602101_145Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/615883/02052021/145Hz/615883_145Hz_AudioVisual/motion_corrected/processed_trace_final.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/615883/03122021/145Hz/615883_145Hz_AudioVisual/motion_corrected/processed_trace_final.h5']"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize Input Values\n",
    "#\n",
    "Base = '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/'\n",
    "Mice, Days = ([608448,608451,608452], ['01102020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files1 = combineFilenames(Base, Folders, Filenames)\n",
    "#Combine All Filenames into one List\n",
    "Mice, Days = ([611111,611311,602101], ['03112020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files2 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([608450], ['01172020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files3 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([608451,608452,611111], ['07012020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files4 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([612535,602101], ['07022020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files5 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([615883], ['02052021','03122021'])\n",
    "Folders, Filenames = makeFilenames_2(Mice, Days)\n",
    "Files6 = combineFilenames(Base, Folders, Filenames)\n",
    "Files= Files1+Files2+Files3+Files4+Files5+Files6\n",
    "Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_traces_df=loadFiles(Files, 'trace',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>mouse</th>\n",
       "      <th colspan=\"10\" halign=\"left\">608448_01102020</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">615883_03122021</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>cell_num</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>74</th>\n",
       "      <th>75</th>\n",
       "      <th>76</th>\n",
       "      <th>77</th>\n",
       "      <th>78</th>\n",
       "      <th>79</th>\n",
       "      <th>80</th>\n",
       "      <th>81</th>\n",
       "      <th>82</th>\n",
       "      <th>83</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Time</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43195</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43196</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43197</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43198</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43199</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>43200 rows Ã— 3371 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "mouse    608448_01102020                                               ...  \\\n",
       "cell_num              0    1    2    3    4    5    6    7    8    9   ...   \n",
       "Time                                                                   ...   \n",
       "0                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "1                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "2                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "3                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "4                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "...                  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "43195                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "43196                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "43197                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "43198                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "43199                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...   \n",
       "\n",
       "mouse    615883_03122021                                               \n",
       "cell_num              74   75   76   77   78   79   80   81   82   83  \n",
       "Time                                                                   \n",
       "0                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "1                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4                    0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...                  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "43195                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "43196                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "43197                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "43198                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "43199                0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[43200 rows x 3371 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "onset_binary_traces_df=loadFiles(Files, 'onset_binary_trace',True)\n",
    "onset_binary_traces_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "binary_traces_df=loadFiles(Files, 'binary_trace',True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFilenames(mouse_numbers, mouse_days):\n",
    "    #Input lists of mouse numbers, days, and sessions to permute to give out directories and dictionary for filename\n",
    "    directories = []\n",
    "    filenames = {}\n",
    "    for m_num in mouse_numbers:\n",
    "        for m_day in mouse_days:\n",
    "            mouse_dir = '{}/{}/{}_145Hz_AudioVisual/motion_corrected/'.format(m_num, m_day,m_num)\n",
    "            directories.append(mouse_dir)\n",
    "                #filenames[mouse_dir] = 'trace_kyleFinal_BinaryVideo.hdf5'\n",
    "            filenames[mouse_dir] = 'LFP_ts.h5'\n",
    "    return directories, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFilenames_2(mouse_numbers, mouse_days):\n",
    "    #Input lists of mouse numbers, days, and sessions to permute to give out directories and dictionary for filename\n",
    "    directories = []\n",
    "    filenames = {}\n",
    "    for m_num in mouse_numbers:\n",
    "        for m_day in mouse_days:\n",
    "            mouse_dir = '{}/{}/145Hz/{}_145Hz_AudioVisual/motion_corrected/'.format(m_num, m_day,m_num)\n",
    "            directories.append(mouse_dir)\n",
    "                #filenames[mouse_dir] = 'trace_kyleFinal_BinaryVideo.hdf5'\n",
    "            filenames[mouse_dir] = 'LFP_ts.h5'\n",
    "    return directories, filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combineFilenames(base, dirs, fnDict):\n",
    "    #Combine Filenames into list for multiple directories with a common base.  fnDict is a dictionary of the filename for each directory\n",
    "    outFiles = []\n",
    "    for d in dirs:\n",
    "        outFiles.append(os.path.join(base+d+fnDict[d]))\n",
    "    return outFiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608448/01102020/608448_145Hz_AudioVisual/motion_corrected/LFP_ts.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608451/01102020/608451_145Hz_AudioVisual/motion_corrected/LFP_ts.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608452/01102020/608452_145Hz_AudioVisual/motion_corrected/LFP_ts.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/611111/03112020/611111_145Hz_AudioVisual/motion_corrected/LFP_ts.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/611311/03112020/611311_145Hz_AudioVisual/motion_corrected/LFP_ts.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/602101/03112020/602101_145Hz_AudioVisual/motion_corrected/LFP_ts.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608450/01172020/608450_145Hz_AudioVisual/motion_corrected/LFP_ts.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608451/07012020/608451_145Hz_AudioVisual/motion_corrected/LFP_ts.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/608452/07012020/608452_145Hz_AudioVisual/motion_corrected/LFP_ts.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/611111/07012020/611111_145Hz_AudioVisual/motion_corrected/LFP_ts.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/612535/07022020/612535_145Hz_AudioVisual/motion_corrected/LFP_ts.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/602101/07022020/602101_145Hz_AudioVisual/motion_corrected/LFP_ts.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/615883/02052021/145Hz/615883_145Hz_AudioVisual/motion_corrected/LFP_ts.h5',\n",
       " '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/615883/03122021/145Hz/615883_145Hz_AudioVisual/motion_corrected/LFP_ts.h5']"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Initialize Input Values\n",
    "#\n",
    "Base = '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/'\n",
    "Mice, Days = ([608448,608451,608452], ['01102020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files1 = combineFilenames(Base, Folders, Filenames)\n",
    "#Combine All Filenames into one List\n",
    "Mice, Days = ([611111,611311,602101], ['03112020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files2 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([608450], ['01172020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files3 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([608451,608452,611111], ['07012020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files4 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([612535,602101], ['07022020'])\n",
    "Folders, Filenames = makeFilenames(Mice, Days)\n",
    "Files5 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([615883], ['02052021','03122021'])\n",
    "Folders, Filenames = makeFilenames_2(Mice, Days)\n",
    "Files6 = combineFilenames(Base, Folders, Filenames)\n",
    "LFP_Files= Files1+Files2+Files3+Files4+Files5+Files6\n",
    "LFP_Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a good way to store stim onsets and offsets \n",
    "def load_onset_offset_2(files,fieldName):\n",
    "    firstf = Files[0]\n",
    "    \n",
    "    firstdir = firstf.split('/')[6]+'_'+firstf.split('/')[7]\n",
    "    f = h5py.File(firstf, 'r')\n",
    "    data=np.array(f[fieldName])-1\n",
    "    data=np.reshape(data,(1,5))\n",
    "    df = pd.DataFrame(data)\n",
    "    df.index=[firstdir]\n",
    "   \n",
    "    for f in files[1:]: #Loop through remaining files and add to DataFrame\n",
    "        fdir = f.split('/')[6]+'_'+f.split('/')[7] #Current Filename/Dir\n",
    "        f = h5py.File(f, 'r')\n",
    "        data=np.array(f[fieldName])-1\n",
    "        data=np.reshape(data,(1,5))\n",
    "        df1 = pd.DataFrame(data)\n",
    "        df1.index=[fdir]\n",
    "        df = pd.concat([df,df1])\n",
    "    df=df.astype(int)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "stim_onsets_df=load_onset_offset_2(LFP_Files,'Stim_onset')\n",
    "stim_offsets_df=load_onset_offset_2(LFP_Files,'Stim_offset')\n",
    "stim_time=stim_offsets_df-stim_onsets_df+1\n",
    "Total_frames_stim = pd.DataFrame(stim_time.sum(axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def makeFilenames_motion(mouse_numbers, mouse_days):\n",
    "    #Input lists of mouse numbers, days, and sessions to permute to give out directories and dictionary for filename\n",
    "    directories = []\n",
    "    filenames = {}\n",
    "    for m_num in mouse_numbers:\n",
    "        for m_day in mouse_days:\n",
    "            mouse_dir = '{}/{}/{}_145Hz_AudioVisual/motion_corrected/'.format(m_num, m_day,m_num)\n",
    "            directories.append(mouse_dir)\n",
    "                #filenames[mouse_dir] = 'trace_kyleFinal_BinaryVideo.hdf5'\n",
    "            filenames[mouse_dir] = 'processed_motion.h5'\n",
    "    return directories, filenames\n",
    "\n",
    "def makeFilenames_motion_2(mouse_numbers, mouse_days):\n",
    "    #Input lists of mouse numbers, days, and sessions to permute to give out directories and dictionary for filename\n",
    "    directories = []\n",
    "    filenames = {}\n",
    "    for m_num in mouse_numbers:\n",
    "        for m_day in mouse_days:\n",
    "            mouse_dir = '{}/{}/145Hz/{}_145Hz_AudioVisual/motion_corrected/'.format(m_num, m_day,m_num)\n",
    "            directories.append(mouse_dir)\n",
    "                #filenames[mouse_dir] = 'trace_kyleFinal_BinaryVideo.hdf5'\n",
    "            filenames[mouse_dir] = 'processed_motion.h5'\n",
    "    return directories, filenames\n",
    "\n",
    "#Initialize Input Values\n",
    "#\n",
    "Base = '/home/hanlabadmins/eng_handata/eng_research_handata2/Sudi_Sridhar/'\n",
    "Mice, Days = ([608448,608451,608452], ['01102020'])\n",
    "Folders, Filenames = makeFilenames_motion(Mice, Days)\n",
    "Files1 = combineFilenames(Base, Folders, Filenames)\n",
    "#Combine All Filenames into one List\n",
    "Mice, Days = ([611111,611311,602101], ['03112020'])\n",
    "Folders, Filenames = makeFilenames_motion(Mice, Days)\n",
    "Files2 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([608450], ['01172020'])\n",
    "Folders, Filenames = makeFilenames_motion(Mice, Days)\n",
    "Files3 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([608451,608452,611111], ['07012020'])\n",
    "Folders, Filenames = makeFilenames_motion(Mice, Days)\n",
    "Files4 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([612535,602101], ['07022020'])\n",
    "Folders, Filenames = makeFilenames_motion(Mice, Days)\n",
    "Files5 = combineFilenames(Base, Folders, Filenames)\n",
    "Mice, Days = ([615883], ['02052021','03122021'])\n",
    "Folders, Filenames = makeFilenames_motion_2(Mice, Days)\n",
    "Files6 = combineFilenames(Base, Folders, Filenames)\n",
    "motion_Files= Files1+Files2+Files3+Files4+Files5+Files6\n",
    "motion_Files\n",
    "\n",
    "motion_df=load_motion(motion_Files,'speed_trace')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1\n",
    "sess_list=[]\n",
    "for mouse, cell_df in onset_binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['602101_03112020', '602101_07022020', '608448_01102020', '608450_01172020', '608451_01102020', '608451_07012020', '608452_01102020', '608452_07012020', '611111_03112020', '611111_07012020', '611311_03112020', '612535_07022020', '615883_02052021', '615883_03122021']\n"
     ]
    }
   ],
   "source": [
    "## Store in .h5 files \n",
    "sess_list=[]\n",
    "for mouse, cell_df in binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)\n",
    "print(sess_list)\n",
    "f1 = h5py.File(\"Event_rate_145Hz_per_min_final.h5\", 'w')\n",
    "label=np.zeros(len(sess_list))\n",
    "for i in np.arange(0,len(sess_list),1):\n",
    "    sess_name=sess_list[i]\n",
    "    mean_p=(baseline_firing_rate_cell_wise(onset_binary_traces_df,sess_name)[1])\n",
    "    mean_p_bin=(baseline_firing_rate_cell_wise(binary_traces_df,sess_name)[1])\n",
    "    if sess_list[i].find('608448') != -1 or sess_list[i].find('608450') != -1 or sess_list[i].find('608452') != -1 or sess_list[i].find('612535') != -1 or sess_list[i].find('615883') != -1: \n",
    "        label[i]=1\n",
    "    if sess_list[i].find('602101') != -1 or sess_list[i].find('608451') != -1 or sess_list[i].find('611311') != -1 or sess_list[i].find('611111') != -1: \n",
    "        label[i]=2\n",
    "    dset1 = f1.create_dataset(sess_list[i]+'_onset', data=mean_p)\n",
    "    dset2 = f1.create_dataset(sess_list[i]+'_bin', data=mean_p_bin)\n",
    "dset3=f1.create_dataset('GCamp_version', data=label)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#608448,608450,608452,612535,615883(check) GCamp7\n",
    "if sess_list[4].find('608448') != -1 or sess_list[4].find('608450') != -1 or sess_list[4].find('608452') != -1 or sess_list[4].find('612535') != -1 or sess_list[4].find('615883') != -1: \n",
    "    print (\"Contains given substring \") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['602101_03112020', '602101_07022020', '608448_01102020', '608450_01172020', '608451_01102020', '608451_07012020', '608452_01102020', '608452_07012020', '611111_03112020', '611111_07012020', '611311_03112020', '612535_07022020', '615883_02052021', '615883_03122021']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanlabadmins/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/hanlabadmins/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "## Store in .h5 files \n",
    "sess_list=[]\n",
    "for mouse, cell_df in binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)\n",
    "print(sess_list)\n",
    "f1 = h5py.File(\"Baseline_mean_corr_145Hz_final.h5\", 'w')\n",
    "label=np.zeros(len(sess_list))\n",
    "mean_corr=np.zeros(len(sess_list))\n",
    "for i in np.arange(0,len(sess_list),1):\n",
    "    sess_name=sess_list[i]\n",
    "    mean_corr[i],_=baseline_corr(sess_name)\n",
    "    if sess_list[i].find('608448') != -1 or sess_list[i].find('608450') != -1 or sess_list[i].find('608452') != -1 or sess_list[i].find('612535') != -1 or sess_list[i].find('615883') != -1: \n",
    "        label[i]=1\n",
    "    if sess_list[i].find('602101') != -1 or sess_list[i].find('608451') != -1 or sess_list[i].find('611311') != -1 or sess_list[i].find('611111') != -1: \n",
    "        label[i]=2\n",
    "    \n",
    "    dset1 = f1.create_dataset(sess_list[i], data=mean_corr[i])\n",
    "dset3=f1.create_dataset('GCamp_version', data=label)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['602101_03112020', '602101_07022020', '608448_01102020', '608450_01172020', '608451_01102020', '608451_07012020', '608452_01102020', '608452_07012020', '611111_03112020', '611111_07012020', '611311_03112020', '612535_07022020', '615883_02052021', '615883_03122021']\n"
     ]
    }
   ],
   "source": [
    "## Store in .h5 files \n",
    "sess_list=[]\n",
    "for mouse, cell_df in binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)\n",
    "print(sess_list)\n",
    "f1 = h5py.File(\"Baseline_mean_corr_145Hz_before_first_stim_final.h5\", 'w')\n",
    "label=np.zeros(len(sess_list))\n",
    "mean_corr=np.zeros(len(sess_list))\n",
    "for i in np.arange(0,len(sess_list),1):\n",
    "    sess_name=sess_list[i]\n",
    "    mean_corr[i],_=corr_before_first_stim(sess_name)\n",
    "    if sess_list[i].find('608448') != -1 or sess_list[i].find('608450') != -1 or sess_list[i].find('608452') != -1 or sess_list[i].find('612535') != -1 or sess_list[i].find('615883') != -1: \n",
    "        label[i]=1\n",
    "    if sess_list[i].find('602101') != -1 or sess_list[i].find('608451') != -1 or sess_list[i].find('611311') != -1 or sess_list[i].find('611111') != -1: \n",
    "        label[i]=2\n",
    "    \n",
    "    dset1 = f1.create_dataset(sess_list[i], data=mean_corr[i])\n",
    "dset3=f1.create_dataset('GCamp_version', data=label)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sess list</th>\n",
       "      <th>Mean baseline corr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>602101_03112020</td>\n",
       "      <td>0.008641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>602101_07022020</td>\n",
       "      <td>0.024874</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>608448_01102020</td>\n",
       "      <td>0.008463</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>608450_01172020</td>\n",
       "      <td>0.010640</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>608451_01102020</td>\n",
       "      <td>0.016344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>608451_07012020</td>\n",
       "      <td>0.008271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>608452_01102020</td>\n",
       "      <td>0.013337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>608452_07012020</td>\n",
       "      <td>0.012879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>611111_03112020</td>\n",
       "      <td>0.048894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>611111_07012020</td>\n",
       "      <td>0.011201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>611311_03112020</td>\n",
       "      <td>0.010940</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>612535_07022020</td>\n",
       "      <td>0.010348</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>615883_02052021</td>\n",
       "      <td>0.007322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>615883_03122021</td>\n",
       "      <td>0.007739</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Sess list  Mean baseline corr\n",
       "0   602101_03112020            0.008641\n",
       "1   602101_07022020            0.024874\n",
       "2   608448_01102020            0.008463\n",
       "3   608450_01172020            0.010640\n",
       "4   608451_01102020            0.016344\n",
       "5   608451_07012020            0.008271\n",
       "6   608452_01102020            0.013337\n",
       "7   608452_07012020            0.012879\n",
       "8   611111_03112020            0.048894\n",
       "9   611111_07012020            0.011201\n",
       "10  611311_03112020            0.010940\n",
       "11  612535_07022020            0.010348\n",
       "12  615883_02052021            0.007322\n",
       "13  615883_03122021            0.007739"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Make a dataframe with sess_list and mean_p\n",
    "df = {'Sess list' : pd.Series(sess_list), 'Mean baseline corr' : pd.Series(mean_corr)}\n",
    "mean_corr_df=pd.DataFrame(df)\n",
    "mean_corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['602101_03112020', '602101_07022020', '608448_01102020', '608450_01172020', '608451_01102020', '608451_07012020', '608452_01102020', '608452_07012020', '611111_03112020', '611111_07012020', '611311_03112020', '612535_07022020', '615883_02052021', '615883_03122021']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/hanlabadmins/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:2534: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[:, None]\n",
      "/home/hanlabadmins/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py:2535: RuntimeWarning: invalid value encountered in true_divide\n",
      "  c /= stddev[None, :]\n"
     ]
    }
   ],
   "source": [
    "## Store in .h5 files \n",
    "sess_list=[]\n",
    "for mouse, cell_df in binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)\n",
    "print(sess_list)\n",
    "f1 = h5py.File(\"Baseline_median_corr_145Hz_final.h5\", 'w')\n",
    "\n",
    "label=np.zeros(len(sess_list))\n",
    "median_corr=np.zeros(len(sess_list))\n",
    "for i in np.arange(0,len(sess_list),1):\n",
    "    sess_name=sess_list[i]\n",
    "    _,median_corr[i]=baseline_corr(sess_name)\n",
    "    if sess_list[i].find('608448') != -1 or sess_list[i].find('608450') != -1 or sess_list[i].find('608452') != -1 or sess_list[i].find('612535') != -1 or sess_list[i].find('615883') != -1: \n",
    "        label[i]=1\n",
    "    if sess_list[i].find('602101') != -1 or sess_list[i].find('608451') != -1 or sess_list[i].find('611311') != -1 or sess_list[i].find('611111') != -1: \n",
    "        label[i]=2\n",
    "    \n",
    "    dset1 = f1.create_dataset(sess_list[i], data=median_corr[i])\n",
    "dset3=f1.create_dataset('GCamp_version', data=label)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['602101_03112020', '602101_07022020', '608448_01102020', '608450_01172020', '608451_01102020', '608451_07012020', '608452_01102020', '608452_07012020', '611111_03112020', '611111_07012020', '611311_03112020', '612535_07022020', '615883_02052021', '615883_03122021']\n"
     ]
    }
   ],
   "source": [
    "## Store in .h5 files \n",
    "sess_list=[]\n",
    "for mouse, cell_df in binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)\n",
    "print(sess_list)\n",
    "f1 = h5py.File(\"Baseline_median_corr_145Hz_before_first_stim_final.h5\", 'w')\n",
    "\n",
    "label=np.zeros(len(sess_list))\n",
    "median_corr=np.zeros(len(sess_list))\n",
    "for i in np.arange(0,len(sess_list),1):\n",
    "    sess_name=sess_list[i]\n",
    "    _,median_corr[i]=corr_before_first_stim(sess_name)\n",
    "    if sess_list[i].find('608448') != -1 or sess_list[i].find('608450') != -1 or sess_list[i].find('608452') != -1 or sess_list[i].find('612535') != -1 or sess_list[i].find('615883') != -1: \n",
    "        label[i]=1\n",
    "    if sess_list[i].find('602101') != -1 or sess_list[i].find('608451') != -1 or sess_list[i].find('611311') != -1 or sess_list[i].find('611111') != -1: \n",
    "        label[i]=2\n",
    "    \n",
    "    dset1 = f1.create_dataset(sess_list[i], data=median_corr[i])\n",
    "dset3=f1.create_dataset('GCamp_version', data=label)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['602101_03112020', '602101_07022020', '608448_01102020', '608450_01172020', '608451_01102020', '608451_07012020', '608452_01102020', '608452_07012020', '611111_03112020', '611111_07012020', '611311_03112020', '612535_07022020', '615883_02052021', '615883_03122021']\n"
     ]
    }
   ],
   "source": [
    "## Store in .h5 files \n",
    "sess_list=[]\n",
    "for mouse, cell_df in binary_traces_df.groupby(level='mouse', axis=1):\n",
    "    sess_list.append(mouse)\n",
    "print(sess_list)\n",
    "f1 = h5py.File(\"Baseline_corr_list_before_first_stim_145Hz_final.h5\", 'w')\n",
    "label=np.zeros(len(sess_list))\n",
    "for i in np.arange(0,len(sess_list),1):\n",
    "    sess_name=sess_list[i]\n",
    "    corr_list=corr_before_first_stim2(sess_name)\n",
    "    \n",
    "    if sess_list[i].find('608448') != -1 or sess_list[i].find('608450') != -1 or sess_list[i].find('608452') != -1 or sess_list[i].find('612535') != -1 or sess_list[i].find('615883') != -1: \n",
    "        label[i]=1\n",
    "    if sess_list[i].find('602101') != -1 or sess_list[i].find('608451') != -1 or sess_list[i].find('611311') != -1 or sess_list[i].find('611111') != -1: \n",
    "        label[i]=2\n",
    "    dset1 = f1.create_dataset(sess_list[i], data=corr_list)\n",
    "dset3=f1.create_dataset('GCamp_version', data=label)\n",
    "f1.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
